{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f98facd",
   "metadata": {},
   "source": [
    "# Sidestory: Word-Vectorization Builder with TF-IDF\n",
    "### Extracting every word's vector representations and store them in a text file\n",
    "Author: Marcus KWAN TH\n",
    "\n",
    "Last updated: 2025-11-15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84f61a",
   "metadata": {},
   "source": [
    "## 1. Prerequisite (same as the main program code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e224587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Add the root folder to sys.path before importing util package\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from util.preprocessing import load_and_preprocess_data\n",
    "\n",
    "# Import all necessary library for word-vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f9a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/15 20:19:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "ss  = SparkSession.builder \\\n",
    "        .appName(\"Marcus TF-IDF Word Dimension Builder\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Add util.zip to PySpark context \n",
    "spark = ss.sparkContext.addPyFile(\"../util.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed068c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/15 20:19:38 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 596\n",
      "Number of testing samples: 397\n",
      "\n",
      "Training 1: wishin i could go to home depot to buy shit to build shit\n",
      "Testing 2: cold war black ops zombie be a damn hype!!!!!!\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training and testing data from the util package\n",
    "train_df = load_and_preprocess_data('../Twitter_data/traindata7.csv')\n",
    "test_df = load_and_preprocess_data('../Twitter_data/testdata7.csv')\n",
    "\n",
    "# Convert Spark DataFrames to Pandas for TF-IDF processing\n",
    "train_pandas = train_df.toPandas()\n",
    "test_pandas = test_df.toPandas()\n",
    "\n",
    "# Extract documents and labels from training data\n",
    "train_documents = train_pandas.iloc[:, 0].astype(str).tolist()\n",
    "train_labels = train_pandas.iloc[:, 1].tolist()\n",
    "\n",
    "# Extract documents and labels from testing data\n",
    "test_documents = test_pandas.iloc[:, 0].astype(str).tolist()\n",
    "test_labels = test_pandas.iloc[:, 1].tolist()\n",
    "\n",
    "print(f\"Number of training samples: {len(train_documents)}\")\n",
    "print(f\"Number of testing samples: {len(test_documents)}\\n\")\n",
    "print(f\"Training 1: {train_documents[0]}\")\n",
    "print(f\"Testing 2: {test_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d5efc",
   "metadata": {},
   "source": [
    "## 2. Perform TF-IDF word vectorization, saves them to dataframe, extract them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06710f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 4046\n",
      "Matrix shape: (993, 4046)\n"
     ]
    }
   ],
   "source": [
    "# Combine all documents for TF-IDF fitting\n",
    "all_documents = train_documents + test_documents\n",
    "\n",
    "# Fit TF-IDF on all documents and get the document-term matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "all_vocab_vectorizer = vectorizer.fit_transform(all_documents)\n",
    "all_vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Check the shape to ensure all words are present\n",
    "print(f\"Vocabulary size: {len(all_vocab)}\")\n",
    "print(f\"Matrix shape: {all_vocab_vectorizer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix: Columns are words, rows are documents\n",
      "\n",
      "      00  000  00303   01   06   07   08   09  0ezqmlg9ik  0wn3frahg  ...  \\\n",
      "0    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "1    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "2    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "3    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "4    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "..   ...  ...    ...  ...  ...  ...  ...  ...         ...        ...  ...   \n",
      "988  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "989  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "990  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "991  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "992  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "\n",
      "     zelda  zero  zion  zkvpbrx5ymk  zla  zoe  zombie  zone  zsmitty   ยบรฐ  \n",
      "0      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "1      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "2      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "3      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "4      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "..     ...   ...   ...          ...  ...  ...     ...   ...      ...  ...  \n",
      "988    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "989    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "990    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "991    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "992    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "\n",
      "[993 rows x 4046 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the TF-IDF matrix to an array format and create a pandas DataFrame\n",
    "df_tfidf = pd.DataFrame(all_vocab_vectorizer.toarray(), columns=all_vocab)\n",
    "\n",
    "print(\"TF-IDF matrix: Columns are words, rows are dimensions\\n\")\n",
    "print(df_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b23f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4046 word vectors (each length 993) to: /Users/MarcussPC/Desktop/Temp/DSAI4205_Project/twitter-sentiment-analysis/model5/output/tfidf_word_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "# Export each word and its TF-IDF vector (dimensions across all documents) to a text file.\n",
    "output_path = os.path.join(root_path + \"/model5/output\", \"tfidf_word_vectors.txt\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    for word in df_tfidf.columns:\n",
    "        vec = df_tfidf[word].to_list()\n",
    "        vec_str = \", \".join(f\"{v:.6f}\" for v in vec) # Format numbers with 6 dp; adjust if necessary.\n",
    "        f.write(f\"{word} [{vec_str}]\\n\")\n",
    "\n",
    "print(f\"Wrote {len(df_tfidf.columns)} word TF-IDF vectors to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
