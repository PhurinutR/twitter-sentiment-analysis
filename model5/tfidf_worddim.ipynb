{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f98facd",
   "metadata": {},
   "source": [
    "# Requested: Word-Vectorization Builder with TF-IDF\n",
    "### Extracting every word's vector representations and store them in a text file\n",
    "Author: Marcus KWAN TH\n",
    "\n",
    "Last updated: 2025-11-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84f61a",
   "metadata": {},
   "source": [
    "## 1. Prerequisite (same as the main program code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e224587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Add the root folder to sys.path before importing util package\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from util.preprocessing import load_and_preprocess_data\n",
    "\n",
    "# Import all necessary library for word-vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3f9a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/16 17:04:09 WARN Utils: Your hostname, Marcuss-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.216 instead (on interface en0)\n",
      "25/11/16 17:04:09 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/16 17:04:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "ss  = SparkSession.builder \\\n",
    "        .appName(\"Marcus TF-IDF Word Dimension Builder\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Add util.zip to PySpark context \n",
    "spark = ss.sparkContext.addPyFile(\"../util.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed068c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/16 17:04:11 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 596\n",
      "Number of testing samples: 397\n",
      "\n",
      "Training 1: wishin i could go to home depot to buy shit to build shit\n",
      "Testing 2: cold war black ops zombie be a damn hype!!!!!!\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training and testing data from the util package\n",
    "train_df = load_and_preprocess_data('../Twitter_data/traindata7.csv')\n",
    "test_df = load_and_preprocess_data('../Twitter_data/testdata7.csv')\n",
    "\n",
    "# Convert Spark DataFrames to Pandas for TF-IDF processing\n",
    "train_pandas = train_df.toPandas()\n",
    "test_pandas = test_df.toPandas()\n",
    "\n",
    "# Extract documents and labels from training data\n",
    "train_documents = train_pandas.iloc[:, 0].astype(str).tolist()\n",
    "train_labels = train_pandas.iloc[:, 1].tolist()\n",
    "\n",
    "# Extract documents and labels from testing data\n",
    "test_documents = test_pandas.iloc[:, 0].astype(str).tolist()\n",
    "test_labels = test_pandas.iloc[:, 1].tolist()\n",
    "\n",
    "print(f\"Number of training samples: {len(train_documents)}\")\n",
    "print(f\"Number of testing samples: {len(test_documents)}\\n\")\n",
    "print(f\"Training 1: {train_documents[0]}\")\n",
    "print(f\"Testing 2: {test_documents[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d5efc",
   "metadata": {},
   "source": [
    "## 2. Perform TF-IDF word vectorization, saves them to dataframe, extract them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06710f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All docs: Vocabulary size: 4046\n",
      "All docs: Matrix shape: (993, 4046)\n",
      "\n",
      "Train docs: Vocabulary size: 2969\n",
      "Train docs: Matrix shape: (596, 2969)\n",
      "\n",
      "Test docs: Vocabulary size: 2209\n",
      "Test docs: Matrix shape: (397, 2209)\n"
     ]
    }
   ],
   "source": [
    "# Combine all documents for TF-IDF fitting\n",
    "all_documents = train_documents + test_documents\n",
    "\n",
    "# Fit TF-IDF on all documents and get the document-term matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "all_vocab_vectorizer = vectorizer.fit_transform(all_documents)\n",
    "all_vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Fit TF-IDF on all documents and get the document-term matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vocab_vectorizer = vectorizer.fit_transform(train_documents)\n",
    "train_vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Fit TF-IDF on all documents and get the document-term matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "test_vocab_vectorizer = vectorizer.fit_transform(test_documents)\n",
    "test_vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Check the shape to ensure all words are present\n",
    "print(f\"All docs: Vocabulary size: {len(all_vocab)}\")\n",
    "print(f\"All docs: Matrix shape: {all_vocab_vectorizer.shape}\\n\")\n",
    "print(f\"Train docs: Vocabulary size: {len(train_vocab)}\")\n",
    "print(f\"Train docs: Matrix shape: {train_vocab_vectorizer.shape}\\n\")\n",
    "print(f\"Test docs: Vocabulary size: {len(test_vocab)}\")\n",
    "print(f\"Test docs: Matrix shape: {test_vocab_vectorizer.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cd7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For all documents: \n",
      "TF-IDF matrix: Columns are words, rows are dimensions\n",
      "\n",
      "      00  000  00303   01   06   07   08   09  0ezqmlg9ik  0wn3frahg  ...  \\\n",
      "0    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "1    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "2    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "3    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "4    0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "..   ...  ...    ...  ...  ...  ...  ...  ...         ...        ...  ...   \n",
      "988  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "989  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "990  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "991  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "992  0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0         0.0        0.0  ...   \n",
      "\n",
      "     zelda  zero  zion  zkvpbrx5ymk  zla  zoe  zombie  zone  zsmitty   ยบรฐ  \n",
      "0      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "1      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "2      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "3      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "4      0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "..     ...   ...   ...          ...  ...  ...     ...   ...      ...  ...  \n",
      "988    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "989    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "990    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "991    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "992    0.0   0.0   0.0          0.0  0.0  0.0     0.0   0.0      0.0  0.0  \n",
      "\n",
      "[993 rows x 4046 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the TF-IDF matrix to an array format and create a pandas DataFrame\n",
    "all_df_tfidf = pd.DataFrame(all_vocab_vectorizer.toarray(), columns=all_vocab)\n",
    "train_df_tfidf = pd.DataFrame(train_vocab_vectorizer.toarray(), columns=train_vocab)\n",
    "test_df_tfidf = pd.DataFrame(test_vocab_vectorizer.toarray(), columns=test_vocab)\n",
    "\n",
    "print(\"For all documents: \\nTF-IDF matrix: Columns are words, rows are dimensions\\n\")\n",
    "print(all_df_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdef101",
   "metadata": {},
   "source": [
    "## 3. Export the TF-IDF vectors to .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b23f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 4046 word TF-IDF vectors to /Users/MarcussPC/Desktop/Temp/DSAI4205_Project/twitter-sentiment-analysis/model5/output/tfidf_word_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "ALL Documents Word Vectors\n",
    "'''\n",
    "# Export each word and its TF-IDF vector (all documents) to a text file.\n",
    "output_path = os.path.join(root_path + \"/model5/output\", \"tfidf_word_vectors.txt\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    for word in all_df_tfidf.columns:\n",
    "        vec = all_df_tfidf[word].to_list()\n",
    "        vec_str = \", \".join(f\"{v:.6f}\" for v in vec) # Format numbers with 6 dp; adjust if necessary.\n",
    "        f.write(f\"{word} [{vec_str}]\\n\")\n",
    "\n",
    "print(f\"Wrote {len(all_df_tfidf.columns)} word TF-IDF vectors to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10844c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2969 word TF-IDF vectors to /Users/MarcussPC/Desktop/Temp/DSAI4205_Project/twitter-sentiment-analysis/model5/output/train_docs_tfidf_word_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TRAIN Documents Word Vectors\n",
    "'''\n",
    "# Export each word and its TF-IDF vector (train documents) to a text file.\n",
    "output_path = os.path.join(root_path + \"/model5/output\", \"train_docs_tfidf_word_vectors.txt\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    for word in train_df_tfidf.columns:\n",
    "        vec = train_df_tfidf[word].to_list()\n",
    "        vec_str = \", \".join(f\"{v:.6f}\" for v in vec) # Format numbers with 6 dp; adjust if necessary.\n",
    "        f.write(f\"{word} [{vec_str}]\\n\")\n",
    "\n",
    "print(f\"Wrote {len(train_df_tfidf.columns)} word TF-IDF vectors to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601d608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 2209 word TF-IDF vectors to /Users/MarcussPC/Desktop/Temp/DSAI4205_Project/twitter-sentiment-analysis/model5/output/test_docs_tfidf_word_vectors.txt\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "TEST Documents Word Vectors\n",
    "'''\n",
    "# Export each word and its TF-IDF vector (test documents) to a text file.\n",
    "output_path = os.path.join(root_path + \"/model5/output\", \"test_docs_tfidf_word_vectors.txt\")\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    for word in test_df_tfidf.columns:\n",
    "        vec = test_df_tfidf[word].to_list()\n",
    "        vec_str = \", \".join(f\"{v:.6f}\" for v in vec) # Format numbers with 6 dp; adjust if necessary.\n",
    "        f.write(f\"{word} [{vec_str}]\\n\")\n",
    "\n",
    "print(f\"Wrote {len(test_df_tfidf.columns)} word TF-IDF vectors to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e617301",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
