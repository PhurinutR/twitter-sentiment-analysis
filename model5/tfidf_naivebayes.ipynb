{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65121d22",
   "metadata": {},
   "source": [
    "# TF-IDF with Naive Bayes Model for Twitter Sentiment Analysis\n",
    "Author: Marcus KWAN TH\n",
    "\n",
    "Last updated: 2025-11-16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044a87be",
   "metadata": {},
   "source": [
    "## 1. TF-IDF Embedding Implementation\n",
    "### Vectorize the pre-processed data into PySpark dataframe using TF-IDF.\n",
    "Libraries: Scikit-learn, PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f303eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The use of this lines is to:\n",
    "1. Prevent PySpark from using a different Python interpreter\n",
    "2. Adding the root path to the sys context for the runtime to properly import util.preprocessing, otherwise, error will occur.\n",
    "based on the testing with Jupyter Notebook.\n",
    "\"\"\"\n",
    "\n",
    "import sys, os\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Add the root folder to sys.path before importing util package\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from util.preprocessing import load_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fd1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary library for TF-IDF embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bed50ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Before running the following code, please ensure to zip the util folder using\n",
    "command: zip -r util.zip util\n",
    "on the root directory.\n",
    "\"\"\"\n",
    "\n",
    "# Initialize Spark Session\n",
    "ss  = SparkSession.builder \\\n",
    "        .appName(\"Marcus TF-IDF Naive-Bayes Model\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Add util.zip to PySpark context \n",
    "spark = ss.sparkContext.addPyFile(\"../util.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69066cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables:\n",
    "col_name = \"tf-idf vectors\"\n",
    "col_label = \"label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07eac53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess training and testing data from the util package\n",
    "# Then convert to Pandas DataFrame for TF-IDF vectorization\n",
    "train_df = load_and_preprocess_data('../Twitter_data/traindata7.csv').toPandas()\n",
    "test_df = load_and_preprocess_data('../Twitter_data/testdata7.csv').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from training data\n",
    "train_documents = train_df.iloc[:, 0].astype(str).tolist()\n",
    "train_labels = train_df.iloc[:, 1].tolist()\n",
    "\n",
    "# Extract documents and labels from testing data\n",
    "test_documents = test_df.iloc[:, 0].astype(str).tolist()\n",
    "test_labels = test_df.iloc[:, 1].tolist()\n",
    "\n",
    "print(f\"Number of training samples: {len(train_documents)}\")\n",
    "print(f\"Number of testing samples: {len(test_documents)}\\n\")\n",
    "\n",
    "print(f\"Training 1: {train_documents[0]}\")\n",
    "print(f\"Testing 2: {test_documents[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2abcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply TF-IDF Vectorizer fit on training data\n",
    "vectorizer = TfidfVectorizer(min_df=4, max_df=0.95, ngram_range=(1,2))\n",
    "train_tfidf_matrix = vectorizer.fit_transform(train_documents)\n",
    "\n",
    "# Apply TF-IDF Vectorizer on testing data\n",
    "test_tfidf_matrix = vectorizer.transform(test_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7473406",
   "metadata": {},
   "source": [
    "#### In a nut-shell,\n",
    "\n",
    "- **`fit()`**: Fit the vectorizer/model to the **training data** and save the vectorizer/model to a variable (returns sklearn.feature_extraction.text.TfidfVectorizer)\n",
    "\n",
    "- **`transform()`**: Use the variable output from `fit()` to transformer **validation/test data** (returns scipy.sparse.csr.csr_matrix)\n",
    "\n",
    "- **`fit_transform()`**: Used to directly transform the **training data**, essentially a combination of `fit()` + `transform()`, thus `fit_transform()`. (returns scipy.sparse.csr.csr_matrix)\n",
    "\n",
    "Source: https://stackoverflow.com/questions/53027864/what-is-the-difference-between-tfidfvectorizer-fit-transfrom-and-tfidf-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e54e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse (doc-term) matrices to dense arrays\n",
    "train_tfidf_dense = train_tfidf_matrix.toarray()\n",
    "test_tfidf_dense = test_tfidf_matrix.toarray()\n",
    "\n",
    "print(f\"TF-IDF matrix shape for (1) Train: {train_tfidf_dense.shape}, (2) Test: {test_tfidf_dense.shape}\")\n",
    "print(f\"Dimension size: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211cbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PySpark DataFrames for training and testing data for later stages\n",
    "train_spark_df = ss.createDataFrame(\n",
    "    [(Vectors.dense(vec), int(lbl)) for vec, lbl in zip(train_tfidf_dense, train_labels)],\n",
    "    [col_name, col_label]\n",
    ")\n",
    "\n",
    "test_spark_df = ss.createDataFrame(\n",
    "    [(Vectors.dense(vec), int(lbl)) for vec, lbl in zip(test_tfidf_dense, test_labels)],\n",
    "    [col_name, col_label]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d36384",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sample training data:\")\n",
    "train_spark_df.show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9036821",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes Data Analytic Model Implementation\n",
    "### Sentiment classification using Naive Bayes model using PySpark.\n",
    "Libraries: Pyspark (Naive Bayes classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b2b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for Naive Bayes classification\n",
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dedde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Naive Bayes model on training data\n",
    "nb = NaiveBayes(featuresCol=col_name, labelCol=col_label, modelType=\"multinomial\", smoothing=1.0)\n",
    "model = nb.fit(train_spark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce83e5df",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "- **Cannot** use `bernoulli` for the modelType of NaiveBayes as it is only suitable for binary classification.\n",
    "- Smoothing (range: [0.0, 1.0]) seems doesn't improve the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244607a0",
   "metadata": {},
   "source": [
    "## 3. Simple Evaluation\n",
    "### Examine the performance of the TFIDF-NaivaBayes combination with training and testing loss with accuracy.\n",
    "Libraries: Pyspark (UDF and evaluation), Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f97b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for evaluation\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878d4e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract probability of the true class for each test sample\n",
    "def get_prob(probability, label):\n",
    "    return float(probability[int(label)])\n",
    "get_prob_udf = udf(get_prob, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091357ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions\n",
    "train_predictions = model.transform(train_spark_df)\n",
    "train_predictions = train_predictions.withColumn(\n",
    "    \"true_prob\", get_prob_udf(col(\"probability\"), col(col_label))\n",
    ")\n",
    "\n",
    "# Testing predictions\n",
    "test_predictions = model.transform(test_spark_df)\n",
    "test_predictions = test_predictions.withColumn(\n",
    "    \"true_prob\", get_prob_udf(col(\"probability\"), col(col_label))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Accuracy and loss Evaluation\n",
    "\"\"\"\n",
    "# Evaluators of the accuracy and loss using PySpark\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=col_label, predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "loss_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=col_label, predictionCol=\"prediction\", metricName=\"logLoss\"\n",
    ")\n",
    "\n",
    "train_loss = loss_evaluator.evaluate(train_predictions)\n",
    "test_loss = loss_evaluator.evaluate(test_predictions)\n",
    "train_accuracy = accuracy_evaluator.evaluate(train_predictions)\n",
    "test_accuracy = accuracy_evaluator.evaluate(test_predictions)\n",
    "\n",
    "# Result\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Testing Loss: {test_loss:.4f}\\n\")\n",
    "print(f\"Train set accuracy = {train_accuracy:.4f}\")\n",
    "print(f\"Test set accuracy = {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c424d36",
   "metadata": {},
   "source": [
    "## 4. Preliminary Result\n",
    "\n",
    "### Control:\n",
    "**1. TfidfVectorizer(min_df=2, max_df=0.95)**\n",
    "\n",
    "**2. modelType=\"multinomial\"**\n",
    "\n",
    "###  Accuracy result captures:\n",
    "1. Control\n",
    "\n",
    "Train loss: 0.9160, accuracy: 78.52%; Testing loss: 1.2395, accuracy: 47.61%.\n",
    "\n",
    "2. min_df = 4\n",
    "\n",
    "Train loss: 0.9732, accuracy: 73.32; Testing loss: 1.2277, accuracy: 48.36%.\n",
    "\n",
    "3. min_df = 8\n",
    "\n",
    "Train loss: 1.0532, accuracy: 64.43%; Testing loss: 1.2383, accuracy: 47.36%.\n",
    "\n",
    "4. max_df = 0.75\n",
    "\n",
    "Train loss: 0.9160, accuracy: 78.52%; Testing loss: 1.2395, accuracy: 47.61%.\n",
    "\n",
    "5. max_df = 0.45\n",
    "\n",
    "Train loss: 0.9135, accuracy: 79.36%; Testing loss: 1.2402, accuracy: 47.61%.\n",
    "\n",
    "6. ngram_range=(1,2)\n",
    "\n",
    "Train loss: 0.8619, accuracy: 82.72%; Testing loss: 1.2345, accuracy: 48.61%.\n",
    "\n",
    "7. ngram_range=(1,3)\n",
    "\n",
    "Train loss: 0.8559, accuracy: 82.89%; Testing loss: 1.2367, accuracy: 47.10%.\n",
    "\n",
    "8. modelType=\"complement\"\n",
    "\n",
    "Train loss: 1.0443, accuracy: 89.60%; Testing loss: 1.2878, accuracy: 47.61%.\n",
    "\n",
    "###  Current best result:\n",
    "1. min_df = 4, max_df = 0.95, ngram_range=(1,2)\n",
    "\n",
    "Train loss: 0.9433, accuracy: 75.50%; Testing loss: 1.2211, accuracy: 50.63%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc9a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a few prediction results with probabilities\n",
    "test_predictions.select(col_name, \"label\", \"prediction\", \"probability\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a58d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818f2cdd",
   "metadata": {},
   "source": [
    "## Appendix:\n",
    "### Methods to Optimize TF-IDF and Naive Bayes Models\n",
    "\n",
    "**TF-IDF Optimization:**\n",
    "- **Tune Parameters:**\n",
    "  - Adjust `max_features`, `min_df`, `max_df` in `TfidfVectorizer` to control vocabulary size and filter rare/common terms.\n",
    "  - Try different `ngram_range` values (e.g., `(1,2)` for unigrams and bigrams).\n",
    "  - Experiment with and without `stop_words='english'`.\n",
    "- **Text Preprocessing:**\n",
    "  - Normalize text (lowercase, remove punctuation, stemming/lemmatization).\n",
    "  - Remove or correct misspellings and special characters.\n",
    "\n",
    "**Naive Bayes Optimization:**\n",
    "- **Model Type:**\n",
    "  - Try different `modelType` options: `multinomial`, `bernoulli`, `complement`.\n",
    "- **Class Imbalance:**\n",
    "  - If classes are imbalanced, consider resampling or adjusting class weights.\n",
    "- **Feature Selection:**\n",
    "  - Remove low-importance features or use dimensionality reduction (e.g., PCA).\n",
    "\n",
    "**General Approaches:**\n",
    "- **Cross-Validation:**\n",
    "  - Use cross-validation to tune hyperparameters and avoid overfitting.\n",
    "- **Ensemble Methods:**\n",
    "  - Combine predictions from multiple models (e.g., voting, stacking).\n",
    "- **Error Analysis:**\n",
    "  - Analyze misclassified samples to improve preprocessing or feature engineering.\n",
    "\n",
    "**Example: Tuning TF-IDF and Naive Bayes**\n",
    "```python\n",
    "# Example: Try bigrams and different min_df\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), min_df=4, max_df=0.75)\n",
    "train_tfidf_matrix = vectorizer.fit_transform(train_documents)\n",
    "test_tfidf_matrix = vectorizer.transform(test_documents)\n",
    "\n",
    "# Example: Try different Naive Bayes model types\n",
    "nb = NaiveBayes(featuresCol=col_name, labelCol=\"label\", modelType=\"multinomial\")\n",
    "model = nb.fit(train_spark_df)\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
