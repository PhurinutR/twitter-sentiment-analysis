{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "044a87be",
   "metadata": {},
   "source": [
    "# TF-IDF Embedding Implementation\n",
    "### Vectorize the pre-processed data into PySpark dataframe using TF-IDF.\n",
    "Libraries: Scikit-learn, PySpark\n",
    "\n",
    "Author: Marcus KWAN TH\n",
    "\n",
    "Last updated: 2025-11-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f303eab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "# Prevent PySpark from using a different Python interpreter\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "# Add the root folder to sys.path before importing util package\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)\n",
    "\n",
    "from util.preprocessing import load_and_preprocess_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93fd1d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary library for TF-IDF embedding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bed50ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/14 23:37:57 WARN Utils: Your hostname, Marcuss-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.216 instead (on interface en0)\n",
      "25/11/14 23:37:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/14 23:37:57 WARN Utils: Your hostname, Marcuss-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.216 instead (on interface en0)\n",
      "25/11/14 23:37:57 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/14 23:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/14 23:37:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Initialize Spark Session\n",
    "ss  = SparkSession.builder \\\n",
    "        .appName(\"Marcus TF-IDF\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Add util.zip to PySpark context \n",
    "# (Please build the util.zip first!)\n",
    "spark = ss.sparkContext.addPyFile(\"../util.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07eac53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/14 23:37:59 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess training and testing data from the util package\n",
    "train_df = load_and_preprocess_data('../Twitter_data/traindata7.csv')\n",
    "test_df = load_and_preprocess_data('../Twitter_data/testdata7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbe54d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrames to Pandas for TF-IDF processing\n",
    "train_pandas = train_df.toPandas()\n",
    "test_pandas = test_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19f3465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract documents and labels from training data\n",
    "train_documents = train_pandas.iloc[:, 0].astype(str).tolist()\n",
    "train_labels = train_pandas.iloc[:, 1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3d55427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 596\n",
      "Testing samples: 397\n"
     ]
    }
   ],
   "source": [
    "# Extract documents and labels from testing data\n",
    "test_documents = test_pandas.iloc[:, 0].astype(str).tolist()\n",
    "test_labels = test_pandas.iloc[:, 1].tolist()\n",
    "\n",
    "print(f\"Training samples: {len(train_documents)}\")\n",
    "print(f\"Testing samples: {len(test_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2abcd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Apply TF-IDF Vectorizer - fit on training data only ===\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english', min_df=2, max_df=0.95)\n",
    "train_tfidf_matrix = vectorizer.fit_transform(train_documents)\n",
    "test_tfidf_matrix = vectorizer.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e54e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix shape - Train: (596, 862), Test: (397, 862)\n",
      "Vocabulary size: 862\n"
     ]
    }
   ],
   "source": [
    "# Convert sparse matrices to dense arrays\n",
    "train_tfidf_dense = train_tfidf_matrix.toarray()\n",
    "test_tfidf_dense = test_tfidf_matrix.toarray()\n",
    "\n",
    "print(f\"TF-IDF matrix shape - Train: {train_tfidf_dense.shape}, Test: {test_tfidf_dense.shape}\")\n",
    "print(f\"Vocabulary size: {len(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211cbc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Create PySpark DataFrames ===\n",
    "train_spark_df = ss.createDataFrame(\n",
    "    [(Vectors.dense(vec), int(lbl)) for vec, lbl in zip(train_tfidf_dense, train_labels)],\n",
    "    [\"tfidf_vector\", \"label\"]\n",
    ")\n",
    "\n",
    "test_spark_df = ss.createDataFrame(\n",
    "    [(Vectors.dense(vec), int(lbl)) for vec, lbl in zip(test_tfidf_dense, test_labels)],\n",
    "    [\"tfidf_vector\", \"label\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9036821",
   "metadata": {},
   "source": [
    "# Naive Bayes Data Analytic Model Implementation\n",
    "### Sentiment classification using Naive Bayes model using PySpark.\n",
    "Libraries: Pyspark (classification and evaluator)\n",
    "\n",
    "Author: Marcus KWAN TH\n",
    "\n",
    "Last updated: 2025-11-14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19b2b605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Import necessary libraries for Naive Bayes classification ===\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dedde4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes model on training data\n",
    "nb = NaiveBayes(featuresCol=\"tfidf_vector\", labelCol=\"label\", modelType=\"multinomial\")\n",
    "\n",
    "model = nb.fit(train_spark_df)\n",
    "predictions = model.transform(test_spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e1e63d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/14 23:38:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+--------------------+\n",
      "|        tfidf_vector|label|prediction|         probability|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "|[0.0,0.0,0.0,0.0,...|    0|       0.0|[0.47980935240653...|\n",
      "|[0.0,0.0,0.0,0.0,...|    0|       0.0|[0.32839533147455...|\n",
      "|[0.0,0.0,0.0,0.0,...|    0|       1.0|[0.33358226921136...|\n",
      "|[0.0,0.0,0.0,0.0,...|    0|       3.0|[0.26412771843285...|\n",
      "|[0.0,0.0,0.0,0.0,...|    0|       0.0|[0.35757501298897...|\n",
      "+--------------------+-----+----------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Show a few prediction results\n",
    "predictions.select(\"tfidf_vector\", \"label\", \"prediction\", \"probability\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7903a5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.4710\n"
     ]
    }
   ],
   "source": [
    "# Evaluate accuracy\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    ")\n",
    "accuracy = accuracy_evaluator.evaluate(predictions)\n",
    "print(f\"Test set accuracy = {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BigData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
