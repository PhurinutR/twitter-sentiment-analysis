{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd9ab1a2",
   "metadata": {},
   "source": [
    "# Story board\n",
    "\n",
    "### 1. Data Exploration (yapping + some visualization about dataset) --> Haige\n",
    "### 2. Initialize the baseline model + explain about how to improve it (\"step 1\" of instruction 3) --> Johnny\n",
    "### 3. Initialize the model and explain about the development of each model one by one. (Here you also discuss the \"step 2\" of instruction 3) --> everyone\n",
    "### 4. Compare the best version of everyone's model performance. --> Jason"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f843aa66",
   "metadata": {},
   "source": [
    "## Section 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cceb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63b5d93",
   "metadata": {},
   "source": [
    "## Section 2: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a5147",
   "metadata": {},
   "source": [
    "## Sec 3 Model1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b763c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef124e",
   "metadata": {},
   "source": [
    "## Sec 3 Model2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a02cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a57aac",
   "metadata": {},
   "source": [
    "# Sec 3 Model3: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6758189",
   "metadata": {},
   "source": [
    "## Sec 3 Model4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c4d387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7297633f",
   "metadata": {},
   "source": [
    "## Sec 3 Model5: \n",
    "#### Text Enbedding Model: TF-IDF\n",
    "#### Data Analytics Model: Naive Bayes\n",
    "#### Python Libaraies: Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf9a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "# Initialize the model and explain about the development of each model one by one. (Here you also discuss the \"step 2\" of instruction 3)\n",
    "\n",
    "'''\n",
    "1. Preparation of libraries, dataset paths, and sample texts.\n",
    "'''\n",
    "from model5.package.model import load_saved_model, evaluate_saved_model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pretrain_csv_path = 'Twitter_data/pre_traindata7.csv'\n",
    "train_csv_path = 'Twitter_data/traindata7.csv'\n",
    "test_csv_path = 'Twitter_data/testdata7.csv'\n",
    "\n",
    "sample_texts = [\"I love this!\", \"I hate this!\", \"Sounds alright.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "2. Test with standard model trained with standard dataset.\n",
    "'''\n",
    "# Initialize the models\n",
    "model5_standard = load_saved_model('model5/package/saved_models')\n",
    "\n",
    "model5_standard_tfidf_model: TfidfVectorizer = model5_standard['embedding']\n",
    "model5_standard_nb_model: MultinomialNB = model5_standard['model']\n",
    "\n",
    "# Evaluate the model on training and testing datasets\n",
    "model5_standard_eval_result = evaluate_saved_model(model5_standard, train_csv_path, test_csv_path)\n",
    "\n",
    "model5_standard_train_loss      = model5_standard_eval_result.get('train').get('loss')\n",
    "model5_standard_train_accuracy  = model5_standard_eval_result.get('train').get('accuracy')\n",
    "model5_standard_test_loss       = model5_standard_eval_result.get('test').get('loss')\n",
    "model5_standard_test_accuracy   = model5_standard_eval_result.get('test').get('accuracy')\n",
    "\n",
    "print(\"Evaluation Results for Standard Model:\")\n",
    "print(f\"Train loss: {model5_standard_train_loss}, Train accuracy: {model5_standard_train_accuracy}\")\n",
    "print(f\"Test loss: {model5_standard_test_loss}, Test accuracy: {model5_standard_test_accuracy}\")\n",
    "\n",
    "# Prediction Result\n",
    "embedded_texts = model5_standard_tfidf_model.transform(sample_texts)\n",
    "nb_predictions = model5_standard_nb_model.predict(embedded_texts)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "for t, p in zip(sample_texts, nb_predictions):\n",
    "    print(f\"Text: '{t}' => Predicted Sentiment: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaeb8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "3. Test with standard model trained with pre-trained dataset.\n",
    "'''\n",
    "# Initialize the models\n",
    "model5_pretrain = load_saved_model('model5/package/saved_models_pretrain7')\n",
    "\n",
    "model5_pretrain_tfidf_model: TfidfVectorizer = model5_pretrain['embedding']\n",
    "model5_pretrain_nb_model: MultinomialNB = model5_pretrain['model']\n",
    "\n",
    "# Evaluate the model on training and testing datasets\n",
    "model5_pretrain_eval_result = evaluate_saved_model(model5_pretrain, pretrain_csv_path, test_csv_path)\n",
    "\n",
    "model5_pretrain_train_loss      = model5_pretrain_eval_result.get('train').get('loss')\n",
    "model5_pretrain_train_accuracy  = model5_pretrain_eval_result.get('train').get('accuracy')\n",
    "model5_pretrain_test_loss       = model5_pretrain_eval_result.get('test').get('loss')\n",
    "model5_pretrain_test_accuracy   = model5_pretrain_eval_result.get('test').get('accuracy')\n",
    "\n",
    "print(\"Evaluation Results for Pretrained Model:\")\n",
    "print(f\"Train loss: {model5_pretrain_train_loss}, Train accuracy: {model5_pretrain_train_accuracy}\")\n",
    "print(f\"Test loss: {model5_pretrain_test_loss}, Test accuracy: {model5_pretrain_test_accuracy}\")\n",
    "\n",
    "# Prediction Result\n",
    "embedded_texts = model5_pretrain_tfidf_model.transform(sample_texts)\n",
    "nb_predictions = model5_pretrain_nb_model.predict(embedded_texts)\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "for t, p in zip(sample_texts, nb_predictions):\n",
    "    print(f\"Text: '{t}' => Predicted Sentiment: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c777debd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "313fed82",
   "metadata": {},
   "source": [
    "#### Explanation later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5715d77c",
   "metadata": {},
   "source": [
    "## Sec 3 Model6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5b18b",
   "metadata": {},
   "source": [
    "## Section 4: Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e84b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement here\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
