{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRgBW2gmcoHv",
        "outputId": "ed7ebfd7-d80e-4015-e6b8-504561dbdc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from util.preprocessing import load_and_preprocess_data\n",
        "\n",
        "train_df = load_and_preprocess_data(\"/Twitter_data/traindata7.csv\")\n",
        "test_df = load_and_preprocess_data(\"/Twitter_data/testdata7.csv\")\n",
        "\n",
        "print(\"Train data:\")\n",
        "train_df.show(10)\n",
        "print(\"\\nTest data:\")\n",
        "test_df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G39MPxRGaUTg",
        "outputId": "0d07a713-da02-4129-c9f0-45b47a065c3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data:\n",
            "+--------------------+---------+\n",
            "|              Phrase|Sentiment|\n",
            "+--------------------+---------+\n",
            "|wishin i could go...|        0|\n",
            "|@ verizon i'm hav...|        0|\n",
            "|please don't beli...|        0|\n",
            "|please sort out a...|        0|\n",
            "|feature fix the e...|        0|\n",
            "|disrespectful. an...|        0|\n",
            "|i think the game ...|        0|\n",
            "|fuck hell, you th...|        0|\n",
            "|@ jukinmedia yout...|        0|\n",
            "|omgggg guy very b...|        0|\n",
            "+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n",
            "\n",
            "Test data:\n",
            "+--------------------+---------+\n",
            "|              Phrase|Sentiment|\n",
            "+--------------------+---------+\n",
            "|cold war black op...|        0|\n",
            "|so add a fucking ...|        0|\n",
            "|this be the bad @...|        0|\n",
            "|'s liberal regres...|        0|\n",
            "|so when i try to ...|        0|\n",
            "|my first run a an...|        0|\n",
            "|i'm still not buy...|        0|\n",
            "|fuck verizon. the...|        0|\n",
            "|news: pubg mobile...|        0|\n",
            "|4 hey rhandlerr r...|        0|\n",
            "+--------------------+---------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create entry points to spark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "ss  = SparkSession.builder \\\n",
        "                            .master(\"local[1]\")\\\n",
        "                            .appName(\"SparkByExamples.com\")\\\n",
        "                            .getOrCreate()\n",
        "spark = ss.sparkContext"
      ],
      "metadata": {
        "id": "QXlMbfUSaZjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DFIDF Logistic Regression"
      ],
      "metadata": {
        "id": "dkm3P0ijhzwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"Phrase\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"Sentiment\", maxIter=20)\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, lr])\n",
        "\n",
        "pipeline_model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "v9XLtPcZaiek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipeline_model.transform(test_df)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft4dKnb5gCOP",
        "outputId": "c7bdd03e-4f37-4f89-94dc-118980bf85eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.4106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model.save(\"pipeline_models/baseline\")"
      ],
      "metadata": {
        "id": "pMRRQwQB46Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import PipelineModel\n",
        "\n",
        "# Prepare new data (must be cleaned with your clean_tweets function!)\n",
        "new_data = [(\"I really hate this thing!\",)]\n",
        "columns = [\"Phrase\"]\n",
        "new_df = ss.createDataFrame(new_data, columns)\n",
        "\n",
        "# Clean the new data\n",
        "from util.preprocessing import clean_tweets\n",
        "cleaned_new_df = clean_tweets(new_df, text_column=\"Phrase\")\n",
        "\n",
        "# Predict\n",
        "predictions = pipeline_model.transform(cleaned_new_df)\n",
        "predictions.select(\"Phrase\", \"prediction\").show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAKmol2-ayle",
        "outputId": "3846f06a-70f5-4b17-97d2-93b0c6964d4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+----------+\n",
            "|              Phrase|prediction|\n",
            "+--------------------+----------+\n",
            "|i really hate thi...|       1.0|\n",
            "+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DFIDF, SVM (One vs Rest)"
      ],
      "metadata": {
        "id": "2J2osLwVr5n7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"Phrase\", outputCol=\"words\")\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "svm = LinearSVC(featuresCol=\"features\", labelCol=\"Sentiment\", maxIter=20)\n",
        "ovr = OneVsRest(classifier=svm, labelCol=\"Sentiment\", featuresCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, ovr])\n",
        "\n",
        "pipeline_model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "qGZqqpIp3jRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipeline_model.transform(test_df)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR_Bx8vG5Zev",
        "outputId": "765cd69c-9055-4f8f-910d-a101139b4698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.4358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model.save(\"pipeline_models/dfidf_svm\")"
      ],
      "metadata": {
        "id": "E1bluVZF5edd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Word2Vec, SVM (One vs Rest)"
      ],
      "metadata": {
        "id": "dtl-SIZp5xmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, Word2Vec\n",
        "from pyspark.ml.classification import LinearSVC, OneVsRest\n",
        "\n",
        "tokenizer = Tokenizer(inputCol=\"Phrase\", outputCol=\"words\")\n",
        "word2vec = Word2Vec(inputCol=\"words\", outputCol=\"features\", vectorSize=100, minCount=1)\n",
        "svm = LinearSVC(featuresCol=\"features\", labelCol=\"Sentiment\", maxIter=20)\n",
        "ovr = OneVsRest(classifier=svm, labelCol=\"Sentiment\", featuresCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, word2vec, ovr])\n",
        "\n",
        "pipeline_model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "gBsJEPWl6Nwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pipeline_model.transform(test_df)\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(\n",
        "    labelCol=\"Sentiment\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZ4nLw2B6ajP",
        "outputId": "f5808c64-a267-4326-e877-2c399a54c4ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.3048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model.save(\"pipeline_models/word2vec_svm\")"
      ],
      "metadata": {
        "id": "ocaEn0vF6WLO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}